{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyjD+mamLfvPn6uKquFcYO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magaramol/Logistic-Regression-Implementation/blob/main/DT_verma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gtTan8BoeTKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b015629c-f8aa-4e78-b9e2-573e67fd6c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[19  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 13]]\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Step 2: Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 3: Initialize the Decision Tree Classifier\n",
        "# You can tune hyperparameters like max_depth, min_samples_split, etc.\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Step 4: Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install graphviz pydotplus\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFfhJCu8LbR_",
        "outputId": "7d45113a-8fc1-4a7c-f428-b80aa0c3ad05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: pydotplus in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pydotplus) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import graphviz\n",
        "import pydotplus\n",
        "from IPython.display import Image\n",
        "\n",
        "# Load the dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the Decision Tree model\n",
        "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Export the tree to DOT format\n",
        "dot_data = export_graphviz(\n",
        "    clf,\n",
        "    out_file=None,  # Output as a string, not a file\n",
        "    feature_names=data.feature_names,\n",
        "    class_names=data.target_names,\n",
        "    filled=True,     # Colors the nodes\n",
        "    rounded=True,    # Rounds the node edges\n",
        "    special_characters=True\n",
        ")\n",
        "\n",
        "# Use graphviz to display the DOT format\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree\")  # This saves the tree as a .pdf file named \"decision_tree\"\n",
        "\n",
        "# Display the tree inline (for Jupyter or IPython environments)\n",
        "graph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "BzDkPtSmQRgm",
        "outputId": "2e4dc59f-0abf-429c-aec3-37c204a815f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"550pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 550.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-429 546,-429 546,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M260,-425C260,-425 125,-425 125,-425 119,-425 113,-419 113,-413 113,-413 113,-354 113,-354 113,-348 119,-342 125,-342 125,-342 260,-342 260,-342 266,-342 272,-348 272,-354 272,-354 272,-413 272,-413 272,-419 266,-425 260,-425\"/>\n<text text-anchor=\"start\" x=\"121\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 2.45</text>\n<text text-anchor=\"start\" x=\"157\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.664</text>\n<text text-anchor=\"start\" x=\"147.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 105</text>\n<text text-anchor=\"start\" x=\"134.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 37, 37]</text>\n<text text-anchor=\"start\" x=\"140\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M161,-298.5C161,-298.5 68,-298.5 68,-298.5 62,-298.5 56,-292.5 56,-286.5 56,-286.5 56,-242.5 56,-242.5 56,-236.5 62,-230.5 68,-230.5 68,-230.5 161,-230.5 161,-230.5 167,-230.5 173,-236.5 173,-242.5 173,-242.5 173,-286.5 173,-286.5 173,-292.5 167,-298.5 161,-298.5\"/>\n<text text-anchor=\"start\" x=\"86.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"73.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n<text text-anchor=\"start\" x=\"64\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 0, 0]</text>\n<text text-anchor=\"start\" x=\"71\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165.44,-341.91C157.93,-330.65 149.78,-318.42 142.24,-307.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"145.07,-305.05 136.61,-298.67 139.25,-308.93 145.07,-305.05\"/>\n<text text-anchor=\"middle\" x=\"131.71\" y=\"-319.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M338,-306C338,-306 203,-306 203,-306 197,-306 191,-300 191,-294 191,-294 191,-235 191,-235 191,-229 197,-223 203,-223 203,-223 338,-223 338,-223 344,-223 350,-229 350,-235 350,-235 350,-294 350,-294 350,-300 344,-306 338,-306\"/>\n<text text-anchor=\"start\" x=\"199\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.75</text>\n<text text-anchor=\"start\" x=\"242.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"229.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 74</text>\n<text text-anchor=\"start\" x=\"216\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 37, 37]</text>\n<text text-anchor=\"start\" x=\"218\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M219.56,-341.91C225.43,-333.1 231.7,-323.7 237.76,-314.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"240.85,-316.28 243.49,-306.02 235.03,-312.4 240.85,-316.28\"/>\n<text text-anchor=\"middle\" x=\"248.39\" y=\"-326.84\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#3fe685\" stroke=\"black\" d=\"M247.5,-187C247.5,-187 125.5,-187 125.5,-187 119.5,-187 113.5,-181 113.5,-175 113.5,-175 113.5,-116 113.5,-116 113.5,-110 119.5,-104 125.5,-104 125.5,-104 247.5,-104 247.5,-104 253.5,-104 259.5,-110 259.5,-116 259.5,-116 259.5,-175 259.5,-175 259.5,-181 253.5,-187 247.5,-187\"/>\n<text text-anchor=\"start\" x=\"121.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.6</text>\n<text text-anchor=\"start\" x=\"151\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.059</text>\n<text text-anchor=\"start\" x=\"145.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"136\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 32, 1]</text>\n<text text-anchor=\"start\" x=\"134\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M241.36,-222.91C234.97,-214.01 228.15,-204.51 221.56,-195.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"224.27,-193.1 215.59,-187.02 218.58,-197.19 224.27,-193.1\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#9254e9\" stroke=\"black\" d=\"M419.5,-187C419.5,-187 289.5,-187 289.5,-187 283.5,-187 277.5,-181 277.5,-175 277.5,-175 277.5,-116 277.5,-116 277.5,-110 283.5,-104 289.5,-104 289.5,-104 419.5,-104 419.5,-104 425.5,-104 431.5,-110 431.5,-116 431.5,-116 431.5,-175 431.5,-175 431.5,-181 425.5,-187 419.5,-187\"/>\n<text text-anchor=\"start\" x=\"285.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.75</text>\n<text text-anchor=\"start\" x=\"319\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.214</text>\n<text text-anchor=\"start\" x=\"313.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 41</text>\n<text text-anchor=\"start\" x=\"304\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5, 36]</text>\n<text text-anchor=\"start\" x=\"306\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M299.64,-222.91C306.03,-214.01 312.85,-204.51 319.44,-195.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"322.42,-197.19 325.41,-187.02 316.73,-193.1 322.42,-197.19\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#39e581\" stroke=\"black\" d=\"M109,-68C109,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 109,0 109,0 115,0 121,-6 121,-12 121,-12 121,-56 121,-56 121,-62 115,-68 109,-68\"/>\n<text text-anchor=\"start\" x=\"32.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"19.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\n<text text-anchor=\"start\" x=\"10\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 32, 0]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M139.58,-103.73C128.77,-94.33 117.29,-84.35 106.51,-74.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"108.66,-72.22 98.82,-68.3 104.07,-77.5 108.66,-72.22\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#8139e5\" stroke=\"black\" d=\"M240,-68C240,-68 151,-68 151,-68 145,-68 139,-62 139,-56 139,-56 139,-12 139,-12 139,-6 145,0 151,0 151,0 240,0 240,0 246,0 252,-6 252,-12 252,-12 252,-56 252,-56 252,-62 246,-68 240,-68\"/>\n<text text-anchor=\"start\" x=\"167.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"158\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"148.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n<text text-anchor=\"start\" x=\"147\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M189.85,-103.73C190.53,-95.43 191.25,-86.67 191.94,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"195.43,-78.55 192.76,-68.3 188.46,-77.98 195.43,-78.55\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M395,-68C395,-68 298,-68 298,-68 292,-68 286,-62 286,-56 286,-56 286,-12 286,-12 286,-6 292,0 298,0 298,0 395,0 395,0 401,0 407,-6 407,-12 407,-12 407,-56 407,-56 407,-62 401,-68 395,-68\"/>\n<text text-anchor=\"start\" x=\"318.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"309\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"299.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 4]</text>\n<text text-anchor=\"start\" x=\"294\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M351.52,-103.73C350.91,-95.43 350.27,-86.67 349.66,-78.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"353.15,-78.02 348.93,-68.3 346.17,-78.53 353.15,-78.02\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#853fe6\" stroke=\"black\" d=\"M530,-68C530,-68 437,-68 437,-68 431,-68 425,-62 425,-56 425,-56 425,-12 425,-12 425,-6 431,0 437,0 437,0 530,0 530,0 536,0 542,-6 542,-12 542,-12 542,-56 542,-56 542,-62 536,-68 530,-68\"/>\n<text text-anchor=\"start\" x=\"448\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.059</text>\n<text text-anchor=\"start\" x=\"442.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"433\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 32]</text>\n<text text-anchor=\"start\" x=\"435\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M402.53,-103.73C413.6,-94.33 425.36,-84.35 436.39,-74.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"438.91,-77.44 444.27,-68.3 434.38,-72.1 438.91,-77.44\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7e5507d7f5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 3, 5, 10],               # Try different depths\n",
        "    'min_samples_split': [2, 5, 10],             # Minimum samples to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],               # Minimum samples in a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],    # Number of features to consider for best split\n",
        "    'criterion': ['gini', 'entropy']             # Splitting criteria\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Set up the grid search with cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=clf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,                      # 5-fold cross-validation\n",
        "    n_jobs=-1,                 # Use all available cores\n",
        "    scoring='accuracy'         # Optimize for accuracy\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and parameters\n",
        "best_clf = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Set Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TR2gsEsQYir",
        "outputId": "4804c7a8-363a-46ba-9b3c-3fa6eac46581"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "Best Cross-Validation Accuracy: 0.9333333333333333\n",
            "Test Set Accuracy: 0.9777777777777777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "360 fits failed out of a total of 1080.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "187 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "173 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1466, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.91428571 0.92380952 0.93333333\n",
            " 0.92380952 0.93333333 0.93333333 0.92380952 0.92380952 0.92380952\n",
            " 0.91428571 0.92380952 0.93333333 0.92380952 0.93333333 0.93333333\n",
            " 0.92380952 0.92380952 0.92380952        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952\n",
            " 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952\n",
            " 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.91428571 0.92380952 0.93333333\n",
            " 0.92380952 0.93333333 0.93333333 0.92380952 0.92380952 0.92380952\n",
            " 0.91428571 0.92380952 0.93333333 0.92380952 0.93333333 0.93333333\n",
            " 0.92380952 0.92380952 0.92380952        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.91428571 0.92380952 0.93333333 0.92380952 0.93333333 0.93333333\n",
            " 0.92380952 0.92380952 0.92380952 0.91428571 0.92380952 0.93333333\n",
            " 0.92380952 0.93333333 0.93333333 0.92380952 0.92380952 0.92380952\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.9047619  0.91428571 0.92380952\n",
            " 0.92380952 0.93333333 0.92380952 0.91428571 0.91428571 0.91428571\n",
            " 0.9047619  0.91428571 0.92380952 0.92380952 0.93333333 0.92380952\n",
            " 0.91428571 0.91428571 0.91428571        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952\n",
            " 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952\n",
            " 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952 0.92380952\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.9047619  0.91428571 0.92380952\n",
            " 0.92380952 0.93333333 0.92380952 0.91428571 0.91428571 0.91428571\n",
            " 0.9047619  0.91428571 0.92380952 0.92380952 0.93333333 0.92380952\n",
            " 0.91428571 0.91428571 0.91428571        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.9047619  0.91428571 0.92380952 0.92380952 0.93333333 0.92380952\n",
            " 0.91428571 0.91428571 0.91428571 0.9047619  0.91428571 0.92380952\n",
            " 0.92380952 0.93333333 0.92380952 0.91428571 0.91428571 0.91428571]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 3, 5, 10],               # Try different depths\n",
        "    'min_samples_split': [2, 5, 10],             # Minimum samples to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4],               # Minimum samples in a leaf node\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],    # Number of features to consider for best split\n",
        "    'criterion': ['gini', 'entropy']             # Splitting criteria\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Set up the grid search with cross-validation\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [None, 3, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],  # Removed 'auto'\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Set up the grid search with the corrected parameter grid\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=clf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and parameters\n",
        "best_clf = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred = best_clf.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Set Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBLrbRHzIPN5",
        "outputId": "d6c7b2b0-7656-4fb2-a3e6-342ce5be65ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "Best Cross-Validation Accuracy: 0.9428571428571428\n",
            "Test Set Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3SG8tSa2J__L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}