{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset (Breast Cancer dataset)\n",
        "data = datasets.load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Labels (0 or 1)\n",
        "\n",
        "# Split the dataset into training and test sets (80% training, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (important for logistic regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print evaluation results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "R4XqHWkW5U8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0c586d-7822-4f58-a6a5-e2980f82aa2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9737\n",
            "Confusion Matrix:\n",
            "[[41  2]\n",
            " [ 1 70]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96        43\n",
            "           1       0.97      0.99      0.98        71\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying different hyperparameters for Logistic Regression\n",
        "log_reg = LogisticRegression(\n",
        "    C=0.1,              # Inverse of regularization strength (smaller values = stronger regularization)\n",
        "    penalty='l2',       # Use L2 regularization (can also try 'l1', 'elasticnet', or 'none')\n",
        "    solver='lbfgs',     # Solver algorithm ('lbfgs', 'liblinear', 'newton-cg', 'saga', etc.)\n",
        "    max_iter=200,       # Maximum number of iterations (increase if not converging)\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model with new hyperparameters\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate performance\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluating the model with new hyperparameters\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "5cJfHdphxo75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68788f46-2c4b-47c3-ac2b-5925d6313750"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9825\n",
            "Confusion Matrix:\n",
            "[[41  2]\n",
            " [ 0 71]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98        43\n",
            "           1       0.97      1.00      0.99        71\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.99      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Define a set of hyperparameters to search over\n",
        "# param_grid = {\n",
        "#     'C': [0.01, 0.1, 1, 10, 100],        # Different values of regularization strength\n",
        "#     'penalty': ['l1', 'l2'],             # L1 and L2 regularization (note: 'l1' works only with 'liblinear' or 'saga')\n",
        "#     'solver': ['liblinear', 'lbfgs', 'saga'],  # Different solvers\n",
        "#     'max_iter': [100, 200, 500]          # Maximum number of iterations\n",
        "# }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Train the model with GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Make predictions with the best parameters\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Evaluate the model with best hyperparameters\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Cross-Validation Score: {best_score:.4f}\")\n",
        "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nreBnlIsnXEE",
        "outputId": "3aa62566-1827-42a4-af4d-c40d67c164f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Best Cross-Validation Score: 0.9780\n",
            "Test Set Accuracy: 0.9912\n",
            "Confusion Matrix:\n",
            "[[42  1]\n",
            " [ 0 71]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.99      1.00      0.99        71\n",
            "\n",
            "    accuracy                           0.99       114\n",
            "   macro avg       0.99      0.99      0.99       114\n",
            "weighted avg       0.99      0.99      0.99       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "75 fits failed out of a total of 450.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "75 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1473, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1194, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.90549451        nan 0.77362637 0.96483516 0.94505495 0.94505495\n",
            " 0.90549451        nan 0.77362637 0.96483516 0.94505495 0.94505495\n",
            " 0.90549451        nan 0.77362637 0.96483516 0.94505495 0.94505495\n",
            " 0.96703297        nan 0.96703297 0.97802198 0.97142857 0.97142857\n",
            " 0.96703297        nan 0.96923077 0.97802198 0.97142857 0.97142857\n",
            " 0.96703297        nan 0.96923077 0.97802198 0.97142857 0.97142857\n",
            " 0.97582418        nan 0.97362637 0.97582418 0.97362637 0.97582418\n",
            " 0.97582418        nan 0.97362637 0.97582418 0.97362637 0.97582418\n",
            " 0.97582418        nan 0.97582418 0.97582418 0.97362637 0.97582418\n",
            " 0.96263736        nan 0.97582418 0.97582418 0.97582418 0.97582418\n",
            " 0.96263736        nan 0.97582418 0.97582418 0.97582418 0.97582418\n",
            " 0.96263736        nan 0.97802198 0.97582418 0.97582418 0.97802198\n",
            " 0.96043956        nan 0.97582418 0.96263736 0.95824176 0.97582418\n",
            " 0.96043956        nan 0.97582418 0.96263736 0.95824176 0.97582418\n",
            " 0.95824176        nan 0.97582418 0.96263736 0.95824176 0.97582418]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Define a set of hyperparameters to search over\n",
        "\n",
        "param_grid = [\n",
        "    {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l2'], 'solver': ['lbfgs', 'liblinear', 'saga'], 'max_iter': [100, 200, 500]},\n",
        "    {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1'], 'solver': ['liblinear', 'saga'], 'max_iter': [100, 200, 500]}\n",
        "]\n",
        "\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
        "\n",
        "# Train the model with GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Make predictions with the best parameters\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Evaluate the model with best hyperparameters\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Cross-Validation Score: {best_score:.4f}\")\n",
        "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZYahYp_p4rZ",
        "outputId": "0e13989d-fe6c-481b-8f5d-d13902cd9806"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Best Cross-Validation Score: 0.9780\n",
            "Test Set Accuracy: 0.9912\n",
            "Confusion Matrix:\n",
            "[[42  1]\n",
            " [ 0 71]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        43\n",
            "           1       0.99      1.00      0.99        71\n",
            "\n",
            "    accuracy                           0.99       114\n",
            "   macro avg       0.99      0.99      0.99       114\n",
            "weighted avg       0.99      0.99      0.99       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Best Hyperparameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
        "Best Cross-Validation Score: 0.9780\n",
        "Test Set Accuracy: 0.9912\n",
        "Confusion Matrix:\n",
        "[[42  1]\n",
        " [ 0 71]]\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.98      0.99        43\n",
        "           1       0.99      1.00      0.99        71\n",
        "\n",
        "    accuracy                           0.99       114\n",
        "   macro avg       0.99      0.99      0.99       114\n",
        "weighted avg       0.99      0.99      0.99       114\n",
        "#\n",
        "Best Hyperparameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
        "Best Cross-Validation Score: 0.9780\n",
        "Test Set Accuracy: 0.9912\n",
        "Confusion Matrix:\n",
        "[[42  1]\n",
        " [ 0 71]]\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.98      0.99        43\n",
        "           1       0.99      1.00      0.99        71\n",
        "\n",
        "    accuracy                           0.99       114\n",
        "   macro avg       0.99      0.99      0.99       114\n",
        "weighted avg       0.99      0.99      0.99       114"
      ],
      "metadata": {
        "id": "BW6lv9REuLZ0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Define the distribution of hyperparameters to search over\n",
        "param_distributions = {\n",
        "    'C': stats.uniform(0.01, 100),       # Sampling from a continuous range of C values\n",
        "    'penalty': ['l1', 'l2'],             # Randomly pick between L1 and L2 regularization\n",
        "    'solver': ['liblinear', 'saga'],     # Solvers that support both penalties\n",
        "    'max_iter': [100, 200, 500,1000]          # Maximum number of iterations\n",
        "}\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    log_reg,\n",
        "    param_distributions,\n",
        "    n_iter=100,              # Number of parameter settings to sample\n",
        "    cv=5,                    # 5-fold cross-validation\n",
        "    scoring='accuracy',       # Evaluate by accuracy\n",
        "    n_jobs=-1,                # Use all available cores\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model with RandomizedSearchCV\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "\n",
        "# Make predictions with the best parameters\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "# Evaluate the model with best hyperparameters\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Cross-Validation Score: {best_score:.4f}\")\n",
        "print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roSp0L86uZSB",
        "outputId": "bb6f9af7-0be2-400a-aeba-37708a66f1c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'C': 15.609452033620265, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Best Cross-Validation Score: 0.9780\n",
            "Test Set Accuracy: 0.9825\n",
            "Confusion Matrix:\n",
            "[[42  1]\n",
            " [ 1 70]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98        43\n",
            "           1       0.99      0.99      0.99        71\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.98      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # random search\n",
        "Best Hyperparameters: {'C': 15.609452033620265, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}\n",
        "Best Cross-Validation Score: 0.9780\n",
        "Test Set Accuracy: 0.9825\n",
        "Confusion Matrix:\n",
        "[[42  1]\n",
        " [ 1 70]]\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.98      0.98      0.98        43\n",
        "           1       0.99      0.99      0.99        71\n",
        "\n",
        "    accuracy                           0.98       114\n",
        "   macro avg       0.98      0.98      0.98       114\n",
        "weighted avg       0.98      0.98      0.98       114\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
        "  warnings.warn(\n",
        "\n",
        "\n",
        "                # old\n",
        "\n",
        "\n",
        "\n",
        "Best Hyperparameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
        "Best Cross-Validation Score: 0.9780\n",
        "Test Set Accuracy: 0.9912\n",
        "Confusion Matrix:\n",
        "[[42  1]\n",
        " [ 0 71]]\n",
        "Classification Report:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.98      0.99        43\n",
        "           1       0.99      1.00      0.99        71\n",
        "\n",
        "    accuracy                           0.99       114\n",
        "   macro avg       0.99      0.99      0.99       114\n",
        "weighted avg       0.99      0.99      0.99       114\n"
      ],
      "metadata": {
        "id": "h1GXn-rBvePU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNkcsiHvwFNF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up hyperparameter grid for Elastic Net\n",
        "param_distributions = {\n",
        "    'C': stats.uniform(0.01, 100),  # Inverse of regularization strength\n",
        "    'penalty': ['elasticnet'],  # Use Elastic Net\n",
        "    'solver': ['saga'],  # 'saga' supports Elastic Net\n",
        "    'l1_ratio': stats.uniform(0, 1),  # Ratio between L1 and L2 regularization\n",
        "    'max_iter': [1000]  # Set max_iter to allow convergence\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Set up the Randomized Search\n",
        "random_search = RandomizedSearchCV(\n",
        "    log_reg,\n",
        "    param_distributions,\n",
        "    n_iter=100,  # Number of random combinations to try\n",
        "    scoring='accuracy',\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "\n",
        "# Best cross-validation score\n",
        "print(\"Best Cross-Validation Score:\", random_search.best_score_)\n",
        "\n",
        "# Predict on the test set\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Set Accuracy:\", test_accuracy)\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLgwvIkKxW_j",
        "outputId": "4091be1b-ded0-4198-d692-1f01b0432180"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best Hyperparameters: {'C': 5.818361216819946, 'l1_ratio': 0.8661761457749352, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
            "Best Cross-Validation Score: 0.9780219780219781\n",
            "Test Set Accuracy: 0.9736842105263158\n",
            "Confusion Matrix:\n",
            "[[42  1]\n",
            " [ 2 69]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97        43\n",
            "           1       0.99      0.97      0.98        71\n",
            "\n",
            "    accuracy                           0.97       114\n",
            "   macro avg       0.97      0.97      0.97       114\n",
            "weighted avg       0.97      0.97      0.97       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QnMgWbKHx4PF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}